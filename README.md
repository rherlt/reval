# reval

## Get started quickly:

1. checkout repository
2. create folder _tmp_
3. place files _Llama-2-13b-chat-hf_responses.json_ and _vicuna-33b-v1.3_responses.json_ into _tmp_ folder
4. rename the files to _import_Llama-2-13b-chat-hf_responses.json_ and _import_vicuna-33b-v1.3_responses.json_
5. run ```docker compose up```
6. open http://localhost:8080